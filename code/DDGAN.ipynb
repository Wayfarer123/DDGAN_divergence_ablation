{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db9bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import imageio\n",
    "import einops\n",
    "import torch\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
    "from torchvision.datasets import FashionMNIST\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e69b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from DDPM_gen_vis import *\n",
    "from GAN_modules import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd535870",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: (x - 0.5) * 2)]\n",
    ")\n",
    "batch_size = 64\n",
    "\n",
    "dataset = FashionMNIST(\"./datasets\", download=True, train=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd05687",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDGAN(nn.Module):\n",
    "    def __init__(self, generator, discriminator, n_steps=15, \n",
    "                 min_beta=2e-1, max_beta=9e-1, device=None, \n",
    "                 image_chw=(1, 28, 28), emb_dim=100):\n",
    "        super(DDGAN, self).__init__()\n",
    "        self.n_steps = n_steps\n",
    "        self.device = device\n",
    "        self.image_chw = image_chw\n",
    "        self.generator = generator.to(device)\n",
    "        self.discriminator = discriminator.to(device)\n",
    "        first = torch.tensor(1e-8).to(device)\n",
    "        self.betas = torch.linspace(min_beta, max_beta, n_steps).to(device)\n",
    "        self.betas = torch.cat((first[None], self.betas)).to(device)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alpha_bars = torch.tensor([torch.prod(self.alphas[:i + 1]) for i in range(len(self.alphas))]).to(device)      \n",
    "        self.sigmas_cum = (1 - self.alpha_bars) ** 0.5\n",
    "        self.emb_matr = sinusoidal_embedding(n_steps, emb_dim).to(device)\n",
    "        self.emb_dim = emb_dim\n",
    "        \n",
    "    def forward(self, x0, t, eta=None):\n",
    "        # Make input image more noisy (we can directly skip to the desired step)\n",
    "        n, c, h, w = x0.shape\n",
    "        a_bar = self.alpha_bars[t]\n",
    "\n",
    "        if eta is None:\n",
    "            eta = torch.randn(n, c, h, w).to(self.device)\n",
    "\n",
    "        noisy = a_bar.sqrt().reshape(n, 1, 1, 1) * x0 + (1 - a_bar).sqrt().reshape(n, 1, 1, 1) * eta\n",
    "        return noisy\n",
    "    \n",
    "    def backward(self, x, t, n_st=None):\n",
    "        # Run each image through the network for each timestep t in the vector t.\n",
    "        # The network returns its estimation of the noise that was added.\n",
    "        if n_st is None:\n",
    "            n_st = self.n_steps\n",
    "            emb_matr = self.emb_matr\n",
    "        else:\n",
    "            emb_matr = sinusoidal_embedding(n_st, self.emb_dim).to(self.device)\n",
    "\n",
    "        t = F.embedding(t, emb_matr)\n",
    "        t.requires_grad_(False)\n",
    "        \n",
    "        latent_z = torch.randn_like(x).to(device)\n",
    "\n",
    "        return self.generator(x, t, latent_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef9666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(inp, t, shape):\n",
    "    out = torch.gather(inp, 0, t)\n",
    " \n",
    "    reshape = [shape[0]] + [1] * (len(shape) - 1)\n",
    "    out = out.reshape(*reshape)\n",
    "    return out\n",
    "\n",
    "def q_sample(ddgan, x_start, t, *, noise=None):\n",
    "    \"\"\"\n",
    "    Diffuse the data (t == 0 means diffused for t step)\n",
    "    \"\"\"\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_start)\n",
    "      \n",
    "    x_t = extract(ddgan.alpha_bars**0.5, t, x_start.shape) * x_start + \\\n",
    "          extract(ddgan.sigmas_cum, t, x_start.shape) * noise\n",
    "    \n",
    "    return x_t\n",
    "\n",
    "    \n",
    "def q_sample_pairs(ddgan, x_start, t):\n",
    "    \"\"\"\n",
    "    Generate a pair of disturbed images for training\n",
    "    :param x_start: x_0\n",
    "    :param t: time step t\n",
    "    :return: x_t, x_{t+1}\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_start)\n",
    "    x_t = q_sample(ddgan, x_start, t)\n",
    "    \n",
    "    x_t_plus_one = x_t * extract(ddgan.alphas**0.5, t+1, x_start.shape) + \\\n",
    "                    extract(ddgan.betas**0.5, t+1, x_start.shape) * noise\n",
    "\n",
    "    return x_t, x_t_plus_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a5f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Posterior_Coefficients():\n",
    "    def __init__(self, ddgan, device):\n",
    "        \n",
    "        self.betas = ddgan.betas\n",
    "        \n",
    "        #we don't need the zeros\n",
    "        self.betas = self.betas.type(torch.float32)[1:]\n",
    "        \n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, 0)\n",
    "        self.alphas_cumprod_prev = torch.cat(\n",
    "                                    (torch.tensor([1.], dtype=torch.float32,device=device), self.alphas_cumprod[:-1]), 0\n",
    "                                        )               \n",
    "        self.posterior_variance = self.betas * (1 - self.alphas_cumprod_prev) / (1 - self.alphas_cumprod)\n",
    "        \n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas_cumprod = torch.rsqrt(self.alphas_cumprod)\n",
    "        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1 / self.alphas_cumprod - 1)\n",
    "        \n",
    "        self.posterior_mean_coef1 = (self.betas * torch.sqrt(self.alphas_cumprod_prev) / (1 - self.alphas_cumprod))\n",
    "        self.posterior_mean_coef2 = ((1 - self.alphas_cumprod_prev) * torch.sqrt(self.alphas) / (1 - self.alphas_cumprod))\n",
    "        \n",
    "        self.posterior_log_variance_clipped = torch.log(self.posterior_variance.clamp(min=1e-20))\n",
    "        \n",
    "def sample_posterior(coefficients, x_0, x_t, t):\n",
    "    \n",
    "    def q_posterior(x_0, x_t, t):\n",
    "        mean = (\n",
    "            extract(coefficients.posterior_mean_coef1, t, x_t.shape) * x_0\n",
    "            + extract(coefficients.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        var = extract(coefficients.posterior_variance, t, x_t.shape)\n",
    "        log_var_clipped = extract(coefficients.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return mean, var, log_var_clipped\n",
    "    \n",
    "  \n",
    "    def p_sample(x_0, x_t, t):\n",
    "        mean, _, log_var = q_posterior(x_0, x_t, t)\n",
    "        \n",
    "        noise = torch.randn_like(x_t)\n",
    "        \n",
    "        nonzero_mask = (1 - (t == 0).type(torch.float32))\n",
    "\n",
    "        return mean + nonzero_mask[:,None,None,None] * torch.exp(0.5 * log_var) * noise\n",
    "    \n",
    "    sample_x_pos = p_sample(x_0, x_t, t)\n",
    "    \n",
    "    return sample_x_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b22633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(ddgan, loader, n_epochs, optimizerG, optimizerD, device,\n",
    "                  schedulerG=None, schedulerD=None, store_path=\"ddgan_model.pt\"):\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    n_steps = ddgan.n_steps\n",
    "    netG = ddgan.generator\n",
    "    netD = ddgan.discriminator\n",
    "\n",
    "    pos_coeff = Posterior_Coefficients(ddgan, device)\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs), desc=f\"Training progress\", colour=\"#00ff00\"):\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}')\n",
    "        \n",
    "        epoch_errG = 0.0\n",
    "        epoch_errD = 0.0\n",
    "           \n",
    "        for step, batch in enumerate(tqdm(loader, leave=False, desc=f\"Epoch {epoch + 1}/{n_epochs}\", colour=\"#005500\")):\n",
    "            \n",
    "            x0 = batch[0].to(device)\n",
    "            n = len(x0)\n",
    "            \n",
    "            t = torch.randint(0, n_steps, (n,)).to(device)\n",
    "            \n",
    "            netD.zero_grad()\n",
    "            x_t, x_tp1 = q_sample_pairs(ddgan, x0, t)\n",
    "            x_t.requires_grad = True\n",
    "            \n",
    "            #train D with real            \n",
    "            D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
    "            errD_real = (F.softplus(-D_real)).mean()\n",
    "            \n",
    "            errD_real.backward(retain_graph=True)\n",
    "                    \n",
    "            #train D with fake from G\n",
    "            latent_z = torch.randn(n, netG.zsize).to(device)\n",
    "            \n",
    "            x_0_predict = netG(x_tp1, t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "            \n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "            \n",
    "            errD_fake = (F.softplus(output)).mean()\n",
    "            errD_fake.backward()\n",
    "            \n",
    "            errD = errD_real.detach() + errD_fake.detach()\n",
    "            optimizerD.step()\n",
    "            \n",
    "            \n",
    "            #train G without D\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            \n",
    "            t = torch.randint(0, n_steps, (n,)).to(device)\n",
    "            \n",
    "            x_t, x_tp1 = q_sample_pairs(ddgan, x0, t)\n",
    "            \n",
    "            latent_z = torch.randn(n, netG.zsize).to(device)\n",
    "            \n",
    "            \n",
    "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "            \n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "               \n",
    "            \n",
    "            errG = (F.softplus(-output)).mean()\n",
    "            \n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            epoch_errG += errG.detach() * n / len(loader.dataset)\n",
    "            epoch_errD += errD.detach() * n / len(loader.dataset)\n",
    "        \n",
    "        if schedulerD is not None:\n",
    "            schedulerD.step()\n",
    "        if schedulerG is not None:\n",
    "            schedulerG.step()\n",
    "\n",
    "        log_string = f\"G loss: {epoch_errG:.4f}, D loss: {epoch_errD:.4f}\"\n",
    "\n",
    "        # Storing the model\n",
    "        torch.save(ddgan.state_dict(), store_path)\n",
    "        print(log_string)\n",
    "        print('-' * 75)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312a0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CustomizableCosineDecayScheduler import CosineDecayWithWarmUpScheduler as CD_scheduler\n",
    "n_steps, min_beta, max_beta = 15, 2e-1, 9e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c5bdcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3fb9def9b644c7b7ac4947342a6f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training progress:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c59fef7f790486fb1fe4aeae15fbe2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/40:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    del generator\n",
    "except: pass\n",
    "try:\n",
    "    del discriminator\n",
    "except: pass\n",
    "try:\n",
    "    del ddgan\n",
    "except: pass\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "generator = Generator(time_emb_dim=20, n_steps=n_steps, device=device, zsize=100)\n",
    "discriminator = Discriminator(time_emb_dim=20, n_steps=n_steps, device=device)\n",
    "\n",
    "\n",
    "ddgan = DDGAN(generator, discriminator, n_steps=n_steps, \n",
    "              min_beta=min_beta, max_beta=max_beta, emb_dim=20,\n",
    "              device=device).to(device)\n",
    "\n",
    "optimizerG = optim.Adam(ddgan.generator.parameters(), betas=(0.7, 0.99),\n",
    "                       lr=3e-3)\n",
    "optimizerD = optim.Adam(ddgan.discriminator.parameters(), betas=(0.7, 0.99),\n",
    "                       lr=3e-3)\n",
    "\n",
    "schedulerG = CD_scheduler(optimizerG, \n",
    "                    max_lr=3e-3, min_lr=3e-6, num_step_down=20, \n",
    "                    num_step_up=0, gamma=0.5, alpha=0.3)\n",
    "schedulerD = CD_scheduler(optimizerG, \n",
    "                    max_lr=7e-3, min_lr=3e-6, num_step_down=20, \n",
    "                    num_step_up=0, gamma=0.3, alpha=0.3)\n",
    "\n",
    "ddgan.train()\n",
    "training_loop(ddgan, loader, n_epochs=40, optimizerG=optimizerG, \n",
    "              optimizerD=optimizerD, schedulerG=schedulerG, schedulerD=schedulerD,\n",
    "              device=device, store_path=\"ddgan_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84af921",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_path=\"ddgan_model.pt\"\n",
    "\n",
    "generator = Generator(time_emb_dim=20, n_steps=n_steps, device=device)\n",
    "discriminator = Discriminator(time_emb_dim=20, n_steps=n_steps, device=device)\n",
    "\n",
    "best_model = DDGAN(generator, discriminator, n_steps=n_steps, device = device)\n",
    "best_model.load_state_dict(torch.load(store_path, map_location=device))\n",
    "best_model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94235d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_images(model=None, n_samples=16, device=None,\n",
    "                        c=1, h=28, w=28, n_steps=None):\n",
    "    ddgan = model\n",
    "    torch.cuda.empty_cache()\n",
    "    if n_steps is None:\n",
    "        n_steps = ddgan.n_steps\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            device = ddgan.device\n",
    "            \n",
    "        pos_coeff = Posterior_Coefficients(ddgan, device)\n",
    "        x = torch.randn(n_samples, c, h, w).to(device)\n",
    "\n",
    "        for idx, t in enumerate(tqdm(list(range(n_steps))[::-1], leave=False, desc=\"Steps\", colour=\"#005500\")):\n",
    "\n",
    "            time_tensor = (torch.ones(n_samples,) * t).to(device).long()\n",
    "            latent_z = torch.randn_like(x).to(device)\n",
    "            \n",
    "            x_0_predict = ddgan.generator(x, time_tensor, latent_z)\n",
    "            x = sample_posterior(pos_coeff, x_0_predict, x, time_tensor).detach()\n",
    "\n",
    "\n",
    "    try:\n",
    "        del ddgan\n",
    "    except: pass\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d003561",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "generated = generate_new_images(\n",
    "        best_model,\n",
    "        n_samples=49,\n",
    "        device=device,\n",
    "        n_steps=15\n",
    "    )\n",
    "show_images(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba74e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
