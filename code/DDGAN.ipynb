{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db9bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import imageio\n",
    "import einops\n",
    "import torch\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
    "from torchvision.datasets import FashionMNIST\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb28cb",
   "metadata": {},
   "source": [
    "# TO DO: fix discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb6c04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, title=\"\"):\n",
    "    \"\"\"Shows the provided images as sub-pictures in a square\"\"\"\n",
    "\n",
    "    # Converting images to CPU numpy arrays\n",
    "    if type(images) is torch.Tensor:\n",
    "        images = images.detach().cpu().numpy()\n",
    "\n",
    "    # Defining number of rows and columns\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    rows = int(len(images) ** (1 / 2))\n",
    "    cols = round(len(images) / rows)\n",
    "\n",
    "    # Populating figure with sub-plots\n",
    "    idx = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            fig.add_subplot(rows, cols, idx + 1)\n",
    "\n",
    "            if idx < len(images):\n",
    "                cur_img = np.transpose(images[idx], (1, 2, 0))\n",
    "                cur_img = (cur_img - np.amin(cur_img, axis=(0,1),keepdims=True)) / np.ptp(cur_img, axis=(0,1))                \n",
    "                plt.imshow(cur_img)\n",
    "                idx += 1\n",
    "    fig.suptitle(title, fontsize=30)\n",
    "\n",
    "    # Showing the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd535870",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: (x - 0.5) * 2)]\n",
    ")\n",
    "batch_size = 64\n",
    "\n",
    "dataset = FashionMNIST(\"./datasets\", download=True, train=True, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582d5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_images(ddg, n_samples=16, device=None, frames_per_gif=100, gif_name=\"sampling.gif\", c=1, h=28, w=28):\n",
    "\n",
    "    frame_idxs = np.linspace(0, ddg.n_steps, frames_per_gif).astype(np.uint)\n",
    "    frames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            device = ddg.device\n",
    "\n",
    "        # Starting from random noise\n",
    "        x = torch.randn(n_samples, c, h, w).to(device)\n",
    "\n",
    "        for idx, t in enumerate(list(range(ddg.n_steps))[::-1]):\n",
    "            # Estimating noise to be removed\n",
    "            time_tensor = (torch.ones(n_samples, 1) * t).to(device).long()\n",
    "            eta_theta = ddg.backward(x, time_tensor)\n",
    "\n",
    "            alpha_t = ddg.alphas[t]\n",
    "            alpha_t_bar = ddg.alpha_bars[t]\n",
    "\n",
    "            # Partially denoising the image\n",
    "            x = (1 / alpha_t.sqrt()) * (x - (1 - alpha_t) / (1 - alpha_t_bar).sqrt() * eta_theta)\n",
    "\n",
    "            if t > 0:\n",
    "                z = torch.randn(n_samples, c, h, w).to(device)\n",
    "\n",
    "                # Option 1: sigma_t squared = beta_t\n",
    "                beta_t = ddg.betas[t]\n",
    "                sigma_t = beta_t.sqrt()\n",
    "\n",
    "\n",
    "                # Adding some more noise like in Langevin Dynamics fashion\n",
    "                x = x + sigma_t * z\n",
    "\n",
    "            # Adding frames to the GIF\n",
    "            if idx in frame_idxs or t == 0:\n",
    "                # Putting digits in range [0, 255]\n",
    "                normalized = x.clone()\n",
    "                for i in range(len(normalized)):\n",
    "                    normalized[i] -= torch.min(normalized[i])\n",
    "                    normalized[i] *= 255 / torch.max(normalized[i])\n",
    "\n",
    "                # Reshaping batch (n, c, h, w) to be a (as much as it gets) square frame\n",
    "                frame = einops.rearrange(normalized, \"(b1 b2) c h w -> (b1 h) (b2 w) c\", b1=int(n_samples ** 0.5))\n",
    "                frame = frame.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "                # Rendering frame\n",
    "                frames.append(frame)\n",
    "\n",
    "    # Storing the gif\n",
    "    with imageio.get_writer(gif_name, mode=\"I\") as writer:\n",
    "        for idx, frame in enumerate(frames):\n",
    "            writer.append_data(frame)\n",
    "            if idx == len(frames) - 1:\n",
    "                for _ in range(frames_per_gif // 3):\n",
    "                    writer.append_data(frames[-1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "195e2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBlock(nn.Module):\n",
    "    def __init__(self, shape, in_c, out_c, kernel_size=3, stride=1, \n",
    "                 padding=1, activation=None, normalize=True):\n",
    "        super(MyBlock, self).__init__()\n",
    "        self.ln = nn.LayerNorm(shape)\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size, stride, padding)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size, stride, padding)\n",
    "        self.activation = nn.SiLU() if activation is None else activation\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.ln(x) if self.normalize else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7edd1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(n, d):\n",
    "    # Returns the standard positional embedding\n",
    "    embedding = torch.zeros(n, d)\n",
    "    wk = torch.tensor([1 / 10_000 ** (2 * j / d) for j in range(d)])\n",
    "    wk = wk.reshape((1, d))\n",
    "    t = torch.arange(n).reshape((n, 1))\n",
    "    embedding[:,::2] = torch.sin(t * wk[:,::2])\n",
    "    embedding[:,1::2] = torch.cos(t * wk[:,::2])\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4d046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_steps=4, time_emb_dim=4):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Sinusoidal embedding\n",
    "        self.time_embed = nn.Embedding(n_steps, time_emb_dim)\n",
    "        self.time_embed.weight.data = sinusoidal_embedding(n_steps, time_emb_dim)\n",
    "        self.time_embed.requires_grad_(False)\n",
    "\n",
    "        # First half\n",
    "        self.te1 = self._make_te(time_emb_dim, 1)\n",
    "        self.b1 = nn.Sequential(\n",
    "            MyBlock((1, 28, 28), 1, 15),\n",
    "            MyBlock((15, 28, 28), 15, 15),\n",
    "            MyBlock((15, 28, 28), 15, 15)\n",
    "        )\n",
    "        self.down1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.te2 = self._make_te(time_emb_dim, 15)\n",
    "        self.b2 = nn.Sequential(\n",
    "            MyBlock((15, 14, 14), 15, 30),\n",
    "            MyBlock((30, 14, 14), 30, 30),\n",
    "            MyBlock((30, 14, 14), 30, 30)\n",
    "        )\n",
    "        self.down2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.te3 = self._make_te(time_emb_dim, 30)\n",
    "        self.b3 = nn.Sequential(\n",
    "            MyBlock((30, 7, 7), 30, 60),\n",
    "            MyBlock((60, 7, 7), 60, 60),\n",
    "            MyBlock((60, 7, 7), 60, 60)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(60, 60, 2, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(60, 60, 4, 2, 1)\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.te_mid = self._make_te(time_emb_dim, 60)\n",
    "        self.b_mid = nn.Sequential(\n",
    "            MyBlock((60, 3, 3), 60, 30),\n",
    "            MyBlock((30, 3, 3), 30, 30),\n",
    "            MyBlock((30, 3, 3), 30, 60)\n",
    "        )\n",
    "\n",
    "        # Second half\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(60, 60, 4, 2, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.ConvTranspose2d(60, 60, 2, 1)\n",
    "        )\n",
    "\n",
    "        self.te4 = self._make_te(time_emb_dim, 120)\n",
    "        self.b4 = nn.Sequential(\n",
    "            MyBlock((120, 7, 7), 120, 60),\n",
    "            MyBlock((60, 7, 7), 60, 30),\n",
    "            MyBlock((30, 7, 7), 30, 30)\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(30, 30, 4, 2, 1)\n",
    "        self.te5 = self._make_te(time_emb_dim, 60)\n",
    "        self.b5 = nn.Sequential(\n",
    "            MyBlock((60, 14, 14), 60, 30),\n",
    "            MyBlock((30, 14, 14), 30, 15),\n",
    "            MyBlock((15, 14, 14), 15, 15)\n",
    "        )\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(15, 15, 4, 2, 1)\n",
    "        self.te_out = self._make_te(time_emb_dim, 30)\n",
    "        self.b_out = nn.Sequential(\n",
    "            MyBlock((30, 28, 28), 30, 15),\n",
    "            MyBlock((15, 28, 28), 15, 15),\n",
    "            MyBlock((15, 28, 28), 15, 15, normalize=False)\n",
    "        )\n",
    "\n",
    "        self.conv_out = nn.Conv2d(15, 1, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "\n",
    "        t = self.time_embed(t)\n",
    "        n = len(x)\n",
    "        out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))\n",
    "        out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))\n",
    "        out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1)) \n",
    "\n",
    "        out_mid = self.b_mid(self.down3(out3) + self.te_mid(t).reshape(n, -1, 1, 1))\n",
    "\n",
    "        out4 = torch.cat((out3, self.up1(out_mid)), dim=1)\n",
    "        out4 = self.b4(out4 + self.te4(t).reshape(n, -1, 1, 1)) \n",
    "\n",
    "        out5 = torch.cat((out2, self.up2(out4)), dim=1) \n",
    "        out5 = self.b5(out5 + self.te5(t).reshape(n, -1, 1, 1))\n",
    "\n",
    "        out = torch.cat((out1, self.up3(out5)), dim=1)\n",
    "        out = self.b_out(out + self.te_out(t).reshape(n, -1, 1, 1))\n",
    "\n",
    "        out = self.conv_out(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_te(self, dim_in, dim_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(dim_in, dim_out),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim_out, dim_out)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1f879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_steps=4, time_emb_dim=4):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # Sinusoidal embedding\n",
    "        self.time_embed = nn.Embedding(n_steps, time_emb_dim)\n",
    "        self.time_embed.weight.data = sinusoidal_embedding(n_steps, time_emb_dim)\n",
    "        self.time_embed.requires_grad_(False)\n",
    "\n",
    "        # First half\n",
    "        self.te1 = self._make_te(time_emb_dim, 1)\n",
    "        self.b1 = nn.Sequential(\n",
    "            MyBlock((1, 28, 28), 1, 15),\n",
    "            MyBlock((15, 28, 28), 15, 15),\n",
    "            MyBlock((15, 28, 28), 15, 15)\n",
    "        )\n",
    "        self.down1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.te2 = self._make_te(time_emb_dim, 15)\n",
    "        self.b2 = nn.Sequential(\n",
    "            MyBlock((15, 14, 14), 15, 30),\n",
    "            MyBlock((30, 14, 14), 30, 30),\n",
    "            MyBlock((30, 14, 14), 30, 30)\n",
    "        )\n",
    "        self.down2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.te3 = self._make_te(time_emb_dim, 30)\n",
    "        self.b3 = nn.Sequential(\n",
    "            MyBlock((30, 7, 7), 30, 60),\n",
    "            MyBlock((60, 7, 7), 60, 60),\n",
    "            MyBlock((60, 7, 7), 60, 60)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(60, 60, 2, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(60, 60, 4, 2, 1)\n",
    "        )\n",
    "\n",
    "        # Bottleneck\n",
    "        self.te_mid = self._make_te(time_emb_dim, 60)\n",
    "        self.b_mid = nn.Sequential(\n",
    "            MyBlock((60, 3, 3), 60, 30),\n",
    "            MyBlock((30, 3, 3), 30, 30),\n",
    "            MyBlock((30, 3, 3), 30, 60)\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(3 * 3 * 60, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "\n",
    "        t = self.time_embed(t)\n",
    "        n = len(x)\n",
    "        out1 = self.b1(x + self.te1(t).reshape(n, -1, 1, 1))\n",
    "        out2 = self.b2(self.down1(out1) + self.te2(t).reshape(n, -1, 1, 1))\n",
    "        out3 = self.b3(self.down2(out2) + self.te3(t).reshape(n, -1, 1, 1)) \n",
    "\n",
    "        out_mid = self.b_mid(self.down3(out3) + self.te_mid(t).reshape(n, -1, 1, 1))\n",
    "\n",
    "        out = self.fc_out(out_mid)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_te(self, dim_in, dim_out):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(dim_in, dim_out),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(dim_out, dim_out)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd05687",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDGAN(nn.Module):\n",
    "    def __init__(self, generator, discriminator, n_steps=4, \n",
    "                 min_beta=2e-1, max_beta=9e-1, device=None, \n",
    "                 image_chw=(1, 28, 28)):\n",
    "        super(DDGAN, self).__init__()\n",
    "        self.n_steps = n_steps\n",
    "        self.device = device\n",
    "        self.image_chw = image_chw\n",
    "        self.generator = generator.to(device)\n",
    "        self.discriminator = discriminator.to(device)\n",
    "        self.betas = torch.linspace(min_beta, max_beta, n_steps).to(\n",
    "            device)  # Number of steps is typically in the order of thousands\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alpha_bars = torch.tensor([torch.prod(self.alphas[:i + 1]) for i in range(len(self.alphas))]).to(device)      \n",
    "        self.sigmas_cum = (1 - self.alpha_bars) ** 0.5\n",
    "        \n",
    "    def forward(self, x0, t, eta=None):\n",
    "        # Make input image more noisy (we can directly skip to the desired step)\n",
    "        n, c, h, w = x0.shape\n",
    "        a_bar = self.alpha_bars[t]\n",
    "\n",
    "        if eta is None:\n",
    "            eta = torch.randn(n, c, h, w).to(self.device)\n",
    "\n",
    "        noisy = a_bar.sqrt().reshape(n, 1, 1, 1) * x0 + (1 - a_bar).sqrt().reshape(n, 1, 1, 1) * eta\n",
    "        return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ef9666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(inp, t, shape):\n",
    "    out = torch.gather(inp, 0, t)\n",
    "    reshape = [shape[0]] + [1] * (len(shape) - 1)\n",
    "    out = out.reshape(*reshape)\n",
    "    return out\n",
    "\n",
    "def q_sample(ddgan, x_start, t, *, noise=None):\n",
    "    \"\"\"\n",
    "    Diffuse the data (t == 0 means diffused for t step)\n",
    "    \"\"\"\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_start)\n",
    "      \n",
    "    x_t = extract(ddgan.alpha_bars**0.5, t, x_start.shape) * x_start + \\\n",
    "          extract(ddgan.sigmas_cum, t, x_start.shape) * noise\n",
    "    \n",
    "    return x_t\n",
    "\n",
    "    \n",
    "def q_sample_pairs(ddgan, x_start, t):\n",
    "    \"\"\"\n",
    "    Generate a pair of disturbed images for training\n",
    "    :param x_start: x_0\n",
    "    :param t: time step t\n",
    "    :return: x_t, x_{t+1}\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_start)\n",
    "    x_t = q_sample(ddgan, x_start, t)\n",
    "    x_t_plus_one = extract(ddgan.alphas**0.5, t+1, x_start.shape) * x_t + \\\n",
    "                   extract(ddgan.betas**0.5, t+1, x_start.shape) * noise\n",
    "    \n",
    "    return x_t, x_t_plus_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a5f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Posterior_Coefficients():\n",
    "    def __init__(self, ddgan, device):\n",
    "        \n",
    "        self.betas = ddgan.betas\n",
    "        \n",
    "        #we don't need the zeros\n",
    "        self.betas = self.betas.type(torch.float32)[1:]\n",
    "        \n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, 0)\n",
    "        self.alphas_cumprod_prev = torch.cat(\n",
    "                                    (torch.tensor([1.], dtype=torch.float32,device=device), self.alphas_cumprod[:-1]), 0\n",
    "                                        )               \n",
    "        self.posterior_variance = self.betas * (1 - self.alphas_cumprod_prev) / (1 - self.alphas_cumprod)\n",
    "        \n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas_cumprod = torch.rsqrt(self.alphas_cumprod)\n",
    "        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1 / self.alphas_cumprod - 1)\n",
    "        \n",
    "        self.posterior_mean_coef1 = (self.betas * torch.sqrt(self.alphas_cumprod_prev) / (1 - self.alphas_cumprod))\n",
    "        self.posterior_mean_coef2 = ((1 - self.alphas_cumprod_prev) * torch.sqrt(self.alphas) / (1 - self.alphas_cumprod))\n",
    "        \n",
    "        self.posterior_log_variance_clipped = torch.log(self.posterior_variance.clamp(min=1e-20))\n",
    "        \n",
    "def sample_posterior(coefficients, x_0,x_t, t):\n",
    "    \n",
    "    def q_posterior(x_0, x_t, t):\n",
    "        mean = (\n",
    "            extract(coefficients.posterior_mean_coef1, t, x_t.shape) * x_0\n",
    "            + extract(coefficients.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        var = extract(coefficients.posterior_variance, t, x_t.shape)\n",
    "        log_var_clipped = extract(coefficients.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return mean, var, log_var_clipped\n",
    "    \n",
    "  \n",
    "    def p_sample(x_0, x_t, t):\n",
    "        mean, _, log_var = q_posterior(x_0, x_t, t)\n",
    "        \n",
    "        noise = torch.randn_like(x_t)\n",
    "        \n",
    "        nonzero_mask = (1 - (t == 0).type(torch.float32))\n",
    "\n",
    "        return mean + nonzero_mask[:,None,None,None] * torch.exp(0.5 * log_var) * noise\n",
    "            \n",
    "    sample_x_pos = p_sample(x_0, x_t, t)\n",
    "    \n",
    "    return sample_x_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b22633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(ddgan, loader, n_epochs, optimizerG, optimizerD, device,\n",
    "                  schedulerD=None, schedulerG=None, store_path=\"ddgan_model.pt\"):\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    n_steps = ddgan.n_steps\n",
    "    netG = ddgan.generator\n",
    "    netD = ddgan.discriminator\n",
    "    pos_coeff = Posterior_Coefficients(ddgan, device)\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs), desc=f\"Training progress\", colour=\"#00ff00\"):\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}')\n",
    "        \n",
    "        epoch_errG = 0.0\n",
    "        epoch_errD = 0.0\n",
    "           \n",
    "        for step, batch in enumerate(tqdm(loader, leave=False, desc=f\"Epoch {epoch + 1}/{n_epochs}\", colour=\"#005500\")):\n",
    "\n",
    "            x0 = batch[0].to(device)\n",
    "            n = len(x0)\n",
    "            \n",
    "            t = torch.randint(0, n_steps, (n,)).to(device)\n",
    "            \n",
    "            netD.zero_grad()\n",
    "            x_t, x_tp1 = q_sample_pairs(ddgan, x0, t)\n",
    "            x_t.requires_grad = True\n",
    "            \n",
    "            \n",
    "            #train D with real\n",
    "            D_real = netD(x_t, t, x_tp1.detach()).view(-1)\n",
    "            errD_real = (F.softplus(-D_real)).mean()\n",
    "            \n",
    "            errD_real.backward(retain_graph=True)\n",
    "            \n",
    "            \n",
    "            #train D with fake from G\n",
    "            latent_z = torch.randn_like(x0).to(device)\n",
    "            \n",
    "            x_0_predict = netG(x_tp1, t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "            \n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "            \n",
    "            errD_fake = (F.softplus(output)).mean()\n",
    "            errD_fake.backward()\n",
    "            \n",
    "            errD = errD_real + errD_fake\n",
    "            optimizerD.step()\n",
    "            \n",
    "            \n",
    "            #train G without D\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False\n",
    "            netG.zero_grad()\n",
    "            \n",
    "            \n",
    "            t = torch.randint(0, n_steps, (n,)).to(device)\n",
    "            \n",
    "            x_t, x_tp1 = q_sample_pairs(ddgan, real_data, t)\n",
    "            \n",
    "            latent_z = torch.randn_like(x0).to(device)\n",
    "            \n",
    "            \n",
    "            x_0_predict = netG(x_tp1.detach(), t, latent_z)\n",
    "            x_pos_sample = sample_posterior(pos_coeff, x_0_predict, x_tp1, t)\n",
    "            \n",
    "            output = netD(x_pos_sample, t, x_tp1.detach()).view(-1)\n",
    "               \n",
    "            \n",
    "            errG = (F.softplus(-output)).mean()\n",
    "            \n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "            \n",
    "\n",
    "            epoch_errG += errG * n / len(loader.dataset)\n",
    "            epoch_errD += errD * n / len(loader.dataset)\n",
    "        \n",
    "        if schedulerD is not None:\n",
    "            schedulerD.step()\n",
    "        if schedulerG is not None:\n",
    "            schedulerG.step()\n",
    "\n",
    "        log_string = f\"G loss: {epoch_errG:.4f}, D loss: {epoch_errD:.4f}\"\n",
    "\n",
    "        # Storing the model\n",
    "        if best_loss > epoch_loss:\n",
    "            torch.save(ddgan.state_dict(), store_path)\n",
    "            \n",
    "        print(log_string)\n",
    "        print('-' * 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "312a0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CustomizableCosineDecayScheduler import CosineDecayWithWarmUpScheduler as CD_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac2bc9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882ff019d7e7497aadf576b3624eee43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training progress:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c4361ce2854c0a9dd61c6bbfce71f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 27\u001b[0m\n\u001b[0;32m     22\u001b[0m schedulerD \u001b[38;5;241m=\u001b[39m CD_scheduler(optimizerG, \n\u001b[0;32m     23\u001b[0m                     max_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-4\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, num_step_down\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, \n\u001b[0;32m     24\u001b[0m                     num_step_up\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m     26\u001b[0m ddgan\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 27\u001b[0m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mddgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizerG\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizerG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m              \u001b[49m\u001b[43moptimizerD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizerD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 29\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(ddgan, loader, n_epochs, optimizerG, optimizerD, device, schedulerD, schedulerG, store_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m x_t\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#train D with real\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m D_real \u001b[38;5;241m=\u001b[39m \u001b[43mnetD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_tp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m errD_real \u001b[38;5;241m=\u001b[39m (F\u001b[38;5;241m.\u001b[39msoftplus(\u001b[38;5;241m-\u001b[39mD_real))\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     32\u001b[0m errD_real\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del ddgan\n",
    "except: pass\n",
    "\n",
    "n_steps, min_beta, max_beta = 4, 2e-1, 9e-1\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "ddgan = DDGAN(generator, discriminator, n_steps=n_steps, \n",
    "              min_beta=min_beta, max_beta=max_beta, device=device)\n",
    "\n",
    "optimizerG = optim.Adam(ddgan.generator.parameters(), betas=(0.7, 0.99),\n",
    "                       lr=3e-4)\n",
    "optimizerD = optim.Adam(ddgan.discriminator.parameters(), betas=(0.7, 0.99),\n",
    "                       lr=3e-4)\n",
    "\n",
    "schedulerG = CD_scheduler(optimizerG, \n",
    "                    max_lr=3e-4, min_lr=1e-6, num_step_down=20, \n",
    "                    num_step_up=0, gamma=0.5, alpha=0.3)\n",
    "schedulerD = CD_scheduler(optimizerG, \n",
    "                    max_lr=3e-4, min_lr=1e-6, num_step_down=20, \n",
    "                    num_step_up=0, gamma=0.5, alpha=0.3)\n",
    "\n",
    "ddgan.train()\n",
    "training_loop(ddgan, loader, n_epochs=20, optimizerG=optimizerG, \n",
    "              optimizerD=optimizerD, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921a3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
